{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install transformers\n",
        "# %pip install torch\n",
        "# %pip install matplotlib\n",
        "# %pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA_SllueTsPv",
        "outputId": "e83e8e97-6902-4c77-f244-cf86c6b79f85"
      },
      "outputs": [],
      "source": [
        "#libraries and packages\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "frUMn1dfUEDc",
        "outputId": "98323022-26ad-4eb3-9f2b-2401f5095ab2"
      },
      "outputs": [],
      "source": [
        "#load data\n",
        "df = pd.read_csv('smile-annotations-final.csv', \n",
        "                 names = ['id', 'text', 'category'])\n",
        "\n",
        "#reset index\n",
        "df.set_index('id', inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "He_5ECZ8UGk5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>611857364396965889</th>\n",
              "      <td>@aandraous @britishmuseum @AndrewsAntonio Merc...</td>\n",
              "      <td>nocode</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614484565059596288</th>\n",
              "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614746522043973632</th>\n",
              "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614877582664835073</th>\n",
              "      <td>@Sofabsports thank you for following me back. ...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611932373039644672</th>\n",
              "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                 text category\n",
              "id                                                                            \n",
              "611857364396965889  @aandraous @britishmuseum @AndrewsAntonio Merc...   nocode\n",
              "614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...    happy\n",
              "614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...    happy\n",
              "614877582664835073  @Sofabsports thank you for following me back. ...    happy\n",
              "611932373039644672  @britishmuseum @TudorHistory What a beautiful ...    happy"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#preview\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "msr33SsQUJlX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3085 entries, 611857364396965889 to 611566876762640384\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   text      3085 non-null   object\n",
            " 1   category  3085 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 72.3+ KB\n"
          ]
        }
      ],
      "source": [
        "#info\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "erSEGK7AUORx"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text        0\n",
              "category    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check for null\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gtuzRmnLUP6U"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\"1...2...\" \"non arrÃªte mon brush!\". l.Alma|A favourite custom|1909 @NationalGallery #bonlundi http://t.co/HpjvSJHGhP'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#look at an example\n",
        "df.text.iloc[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "N6OPKRMOUS0H"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "nocode               1572\n",
              "happy                1137\n",
              "not-relevant          214\n",
              "angry                  57\n",
              "surprise               35\n",
              "sad                    32\n",
              "happy|surprise         11\n",
              "happy|sad               9\n",
              "disgust|angry           7\n",
              "disgust                 6\n",
              "sad|disgust             2\n",
              "sad|angry               2\n",
              "sad|disgust|angry       1\n",
              "Name: category, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#count for each class\n",
        "df.category.value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "J4f9ZmlpUVxZ"
      },
      "outputs": [],
      "source": [
        "#drop irrelevent class\n",
        "df = df[~df.category.str.contains('\\|')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gqOLtJXqUXau"
      },
      "outputs": [],
      "source": [
        "\n",
        "#drop irrelevent class\n",
        "df = df[df.category != 'nocode']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "R0vt_9ATUZy5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "happy           1137\n",
              "not-relevant     214\n",
              "angry             57\n",
              "surprise          35\n",
              "sad               32\n",
              "disgust            6\n",
              "Name: category, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#final classes\n",
        "df.category.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JKtuULn3UboX"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\gopal\\anaconda3\\envs\\project\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#plot class distribution\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.countplot(df.category, palette='Spectral')\n",
        "plt.xlabel('Classes')\n",
        "plt.title('Class Distribution')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARXpe3GmUeJ6"
      },
      "outputs": [],
      "source": [
        "#store classes into an array\n",
        "possible_labels = df.category.unique()\n",
        "possible_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBH7r_ZQUj6w"
      },
      "outputs": [],
      "source": [
        "#convert labels into numeric values\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3vbP3vPUlfx"
      },
      "outputs": [],
      "source": [
        "label_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TN4y2Nw1UnAo"
      },
      "outputs": [],
      "source": [
        "#convert labels into numeric values\n",
        "df['label'] = df.category.replace(label_dict)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMXDzb3VUonA"
      },
      "outputs": [],
      "source": [
        "#need equal length sentences\n",
        "#plot hist of sentence length\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot([len(s) for s in df.text], bins=100)\n",
        "plt.title('Sentence Length')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld2eWBdqUqwQ"
      },
      "outputs": [],
      "source": [
        "#find the maximum length\n",
        "max_len = max([len(sent) for sent in df.text])\n",
        "print('Max length: ', max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpypRQ0lUslS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#train test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
        "                                                   df.label.values,\n",
        "                                                   test_size = 0.15,\n",
        "                                                   random_state = 17,\n",
        "                                                   stratify = df.label.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxGGLnJcUv4g"
      },
      "outputs": [],
      "source": [
        "#create new column\n",
        "df['data_type'] = ['not_set'] * df.shape[0]\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZAj0XtHUxxY"
      },
      "outputs": [],
      "source": [
        "#fill in data type\n",
        "df.loc[X_train, 'data_type'] = 'train'\n",
        "df.loc[X_val, 'data_type'] = 'val'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T52P64GCUzRE"
      },
      "outputs": [],
      "source": [
        "df.groupby(['category', 'label', 'data_type']).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5xUYZhMU1Yo"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-GoyH_FU3SI"
      },
      "outputs": [],
      "source": [
        "#load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n",
        "                                         do_lower_case = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_eKHM6cU8T4"
      },
      "outputs": [],
      "source": [
        "#tokenize train set\n",
        "encoded_data_train = tokenizer.batch_encode_plus(df[df.data_type == 'train'].text.values,\n",
        "                                                add_special_tokens = True,\n",
        "                                                return_attention_mask = True,\n",
        "                                                pad_to_max_length = True,\n",
        "                                                max_length = 150,\n",
        "                                                return_tensors = 'pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNHvsgHwU-Pp"
      },
      "outputs": [],
      "source": [
        "#tokenizer val set\n",
        "encoded_data_val = tokenizer.batch_encode_plus(df[df.data_type == 'val'].text.values,\n",
        "                                                #add_special_tokens = True,\n",
        "                                                return_attention_mask = True,\n",
        "                                                pad_to_max_length = True,\n",
        "                                                max_length = 150,\n",
        "                                                return_tensors = 'pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqAjhTg6VAhI"
      },
      "outputs": [],
      "source": [
        "\n",
        "encoded_data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87z5rCf4VCgp"
      },
      "outputs": [],
      "source": [
        "#encode train set\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df[df.data_type == 'train'].label.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVqTZ1euVDEx"
      },
      "outputs": [],
      "source": [
        "#encode val set\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "\n",
        "#convert data type to torch.tensor\n",
        "labels_val = torch.tensor(df[df.data_type == 'val'].label.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uosBq8pKVE9K"
      },
      "outputs": [],
      "source": [
        "input_ids_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Yd8TUL8VHl4"
      },
      "outputs": [],
      "source": [
        "attention_masks_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEj4h1-oVLkC"
      },
      "outputs": [],
      "source": [
        "labels_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGw9dAi2VNRQ"
      },
      "outputs": [],
      "source": [
        "#create dataloader\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                             attention_masks_val, \n",
        "                             labels_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzceLhx7VQbr"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(len(dataset_train))\n",
        "print(len(dataset_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlWzv1OvVQ-o"
      },
      "outputs": [],
      "source": [
        "dataset_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXD4VbMaVTwo"
      },
      "outputs": [],
      "source": [
        "dataset_train.tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzKaA1IUVZNo"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "#load pre-trained BERT\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "                                                      num_labels = len(label_dict),\n",
        "                                                      output_attentions = False,\n",
        "                                                      output_hidden_states = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgedJjtRVbt5"
      },
      "outputs": [],
      "source": [
        "#model summary\n",
        "model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYUJvgjIVdwA"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 4 #since we have limited resource\n",
        "\n",
        "#load train set\n",
        "dataloader_train = DataLoader(dataset_train,\n",
        "                              sampler = RandomSampler(dataset_train),\n",
        "                              batch_size = batch_size)\n",
        "\n",
        "#load val set\n",
        "dataloader_val = DataLoader(dataset_val,\n",
        "                              sampler = RandomSampler(dataset_val),\n",
        "                              batch_size = 32) #since we don't have to do backpropagation for this step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWKeQHj0Vf6q"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "epochs = 10\n",
        "\n",
        "#load optimizer\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                 lr = 1e-5,\n",
        "                 eps = 1e-8) #2e-5 > 5e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2RZITjdVhsw"
      },
      "outputs": [],
      "source": [
        "#load scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                           num_warmup_steps = 0,\n",
        "                                           num_training_steps = len(dataloader_train)*epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrFEuDHnVjvi"
      },
      "outputs": [],
      "source": [
        "#preds = [0.9 0.05 0.05 0 0 0]\n",
        "#preds = [1 0 0 0 0 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60ubHJoaVoFU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#f1 score\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9rgSbDDWh-I"
      },
      "outputs": [],
      "source": [
        "#accuracy score\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    #make prediction\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLWLZknaWkLh"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    #evaluation mode disables the dropout layer \n",
        "    model.eval()\n",
        "    \n",
        "    #tracking variables\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        #load into GPU\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        #define inputs\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2]}\n",
        "\n",
        "        #compute logits\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "        \n",
        "        #compute loss\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        #compute accuracy\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    #compute average loss\n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRVUCWOVW3sq"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NC6wHCxlW59A"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXNjOZyNW7TL"
      },
      "outputs": [],
      "source": [
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "\n",
        "    #set model in train mode\n",
        "    model.train()\n",
        "\n",
        "    #tracking variable\n",
        "    loss_train_total = 0\n",
        "    \n",
        "    #set up progress bar\n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc='Epoch {:1d}'.format(epoch), \n",
        "                        leave=False, \n",
        "                        disable=False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        #set gradient to 0\n",
        "        model.zero_grad()\n",
        "\n",
        "        #load into GPU\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "        #define inputs\n",
        "        inputs = {'input_ids': batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels': batch[2]}\n",
        "        \n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0] #output.loss\n",
        "        loss_train_total +=loss.item()\n",
        "\n",
        "        #backward pass to get gradients\n",
        "        loss.backward()\n",
        "        \n",
        "        #clip the norm of the gradients to 1.0 to prevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        #update optimizer\n",
        "        optimizer.step()\n",
        "\n",
        "        #update scheduler\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
        "    \n",
        "    tqdm.write('\\nEpoch {epoch}')\n",
        "    \n",
        "    #print training result\n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    #evaluate\n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    #f1 score\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (weighted): {val_f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--yrLClSXAdX"
      },
      "outputs": [],
      "source": [
        "outputs.loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf0XZpMAXCxT"
      },
      "outputs": [],
      "source": [
        "outputs.logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al9PvUNqXEfg"
      },
      "outputs": [],
      "source": [
        "#save model\n",
        "model.to(device)\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWs1W8Y5XF2m"
      },
      "outputs": [],
      "source": [
        "#evaluate\n",
        "_, predictions, true_vals = evaluate(dataloader_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoxBieQOXHOE"
      },
      "outputs": [],
      "source": [
        "#get accuracy score\n",
        "accuracy_per_class(predictions, true_vals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s4WaE1NXI04"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "157923cb5c6909fd982eb0e16f1ca822199293dcfb680100b85abe457cc47ea1"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('project')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
