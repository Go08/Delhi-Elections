{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HNL-YRomFYZw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git\n",
            "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to c:\\users\\gopal\\appdata\\local\\temp\\pip-req-build-z3ushmj4\n",
            "Requirement already satisfied: requests[socks] in c:\\users\\gopal\\anaconda3\\lib\\site-packages (from snscrape==0.4.3.20220107.dev45+ged3ea94) (2.25.1)\n",
            "Requirement already satisfied: lxml in c:\\users\\gopal\\anaconda3\\lib\\site-packages (from snscrape==0.4.3.20220107.dev45+ged3ea94) (4.6.3)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\gopal\\anaconda3\\lib\\site-packages (from snscrape==0.4.3.20220107.dev45+ged3ea94) (4.9.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\gopal\\anaconda3\\lib\\site-packages (from snscrape==0.4.3.20220107.dev45+ged3ea94) (3.0.12)\n",
            "Requirement already satisfied: pytz in c:\\users\\gopal\\anaconda3\\lib\\site-packages (from snscrape==0.4.3.20220107.dev45+ged3ea94) (2021.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\gopal\\anaconda3\\lib\\site-packages (from beautifulsoup4->snscrape==0.4.3.20220107.dev45+ged3ea94) (2.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\gopal\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.4.3.20220107.dev45+ged3ea94) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gopal\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.4.3.20220107.dev45+ged3ea94) (2020.12.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gopal\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.4.3.20220107.dev45+ged3ea94) (1.26.4)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\gopal\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.4.3.20220107.dev45+ged3ea94) (4.0.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\gopal\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.4.3.20220107.dev45+ged3ea94) (1.7.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  Running command git clone -q https://github.com/JustAnotherArchivist/snscrape.git 'C:\\Users\\gopal\\AppData\\Local\\Temp\\pip-req-build-z3ushmj4'\n"
          ]
        }
      ],
      "source": [
        "!pip3 install git+https://github.com/JustAnotherArchivist/snscrape.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4xURiK7eFYZ0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd \n",
        "import snscrape.modules.twitter as sntwitter\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EV985QkyFYZ1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2017-03-03 23:37:36+00:00\n",
            "2/4 0\n",
            "2017-03-01 19:08:14+00:00\n",
            "2/4 500\n",
            "2017-02-28 05:36:40+00:00\n",
            "2/4 1000\n",
            "2017-02-26 11:48:06+00:00\n",
            "2/4 1500\n",
            "2017-02-24 17:47:14+00:00\n",
            "2/4 2000\n",
            "2017-02-23 07:07:22+00:00\n",
            "2/4 2500\n",
            "2017-02-22 04:41:25+00:00\n",
            "2/4 3000\n",
            "2017-02-20 09:35:19+00:00\n",
            "2/4 3500\n",
            "2017-02-19 02:51:58+00:00\n",
            "2/4 4000\n",
            "2017-02-17 07:44:24+00:00\n",
            "2/4 4500\n",
            "2017-02-16 01:32:29+00:00\n",
            "2/4 5000\n",
            "2017-02-14 11:48:14+00:00\n",
            "2/4 5500\n",
            "2017-02-13 13:27:39+00:00\n",
            "2/4 6000\n",
            "2017-03-03 15:51:15+00:00\n",
            "4/4 0\n"
          ]
        }
      ],
      "source": [
        "tweets=[]\n",
        "keywords = ['#punjabelections2022','#Punjab', '#PunjabAssembly2022','#पंजाब']\n",
        "queries = []\n",
        "tot = len(keywords)\n",
        "curr = 1\n",
        "for keyword in keywords:\n",
        "    queries.append(keyword + ' since:2017-02-12 until:2017-03-4')\n",
        "df = pd.DataFrame()\n",
        "for query in queries:\n",
        "    # Using TwitterSearchScraper to scrape data and append tweets to list\n",
        "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
        "        if i%500==0:\n",
        "            print(tweet.date)\n",
        "            print(f'{curr}/{tot}', i)\n",
        "        tweets.append([tweet.url, tweet.id, tweet.date, tweet.user.location, tweet.user.username, tweet.user.displayname, tweet.user.verified, tweet.user.followersCount, tweet.user.friendsCount, tweet.lang, tweet.content, tweet.user.description, tweet.likeCount, tweet.retweetCount, tweet.quoteCount, tweet.replyCount, tweet.hashtags])\n",
        "    curr+=1\n",
        "    # Creating a dataframe from the tweets list above\n",
        "    df = df.append(pd.DataFrame(tweets, columns=['url', 'id', 'datetime', 'location', 'username', 'displayname', 'verified', 'followerCount', 'friendsCount', 'language', 'content', 'bio', 'likes', 'retweets', 'quotes', 'comments', 'hashtags']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O1bLGshJFYZ2"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(subset=['content', 'username', 'datetime'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6594, 17)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Common\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U4r-4XN5FYZ2"
      },
      "outputs": [],
      "source": [
        "df.to_csv('pb17_common_12feb04Mar.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "scraper.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "d852527b6d050d324cf703282f4ca02886d6c5070c4479bf6ecfa03b7efd04af"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('main')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
